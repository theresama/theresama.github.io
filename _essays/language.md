---
title: language
layout: default
categories: projects
---

The Role of Language in Mind: A Discussion
--------------

<style>
.text {
    margin-left: 24px;
    font: 14px monospace;
    line-height: 1.5;
}

.name {
    font: 18px monospace;
    font-weight: bold;
    font-variant: small-caps;
}

.action {
    font: 14px serif;
    font-style: italic;
    margin-left: 24px;
}

</style>

Alice, Bob, Caitlin, and David meet in an online chat room for discussing philosophical questions. The prompt for the evening is, “Is language a necessary or sufficient condition for intelligence?”. They each hold a different view on the matter. Conversation ensues.

---

alice: 
{: .name}

Language is both necessary and sufficient as a condition for intelligence. The ability to use a language entails intelligence. This is also the assumption made by Alan Turing in his paper, “Computing Machinery and Intelligence”. He asks the question, “Can computers think?”, and then proposes what is now known as the Turing Test - an “imitation game” where an interrogator has a conversation through typed text and tries to distinguish whether they are speaking to a machine or a person.
{: .text}

If the interrogator cannot tell the difference between a human and a machine, then the machine has intelligence (Turing, 1950). If the machine has a grasp on language, then it would be able to fool the interrogator into believing they are speaking with a human; therefore, language is the necessary and sufficient criterion for assessing intelligence.  
{: .text}

bob:
{: .name}

I agree with you that language is necessary for intelligence, but I don’t think language is sufficient. Have you heard of Searle’s Chinese Room thought experiment? Imagine a man who does not understand Chinese in a room with a set of rules by which to manipulate Chinese characters. He communicates with an outside world by exchanging written words under the door. He can follow the instructions so that he may speak to someone outside the room in Chinese, and they may believe him to understand Chinese, without himself actually understanding Chinese (Searle).
{: .text}

Can it really be considered intelligence on the man’s part, if he does not understand what he is doing? Does the ability to follow a set of instructions necessarily imply that he is intelligent? Understanding is missing from this account of intelligence.  
{: .text}

david:  
{: .name}

I agree with you, Bob on the opinion that the Turing Test, and language by extension, is an insufficient test for intelligence. The Chinese Room shows that the ability to ‘use’ a language can be dissociated from the ability to ‘understand’ a language. He is merely following a set of instructions. If mindlessly following instructions were intelligent, then calculators would have minds. Moreover, the Turning Test assumes that any response by a human mind is intelligent! I mean, have you seen the recent debates between the US presidential nominees?  
{: .text}

alice:  
{: .name}

The man in the Chinese room, may not be capable of understanding Chinese, but the system as a whole does indeed understand Chinese. Thinking of the man as the “mind” would be akin to thinking of a piece of the machine as the entire computer (Cole, 2013).
{: .text}

caitlin:  
{: .name}

Bob, I don’t think you understand what it means to have ‘language’. By ‘language’, we mean any system of symbolic communication with the properties of productivity, systematicity, and compositionality.  
{: .text}

Productivity refers to the way that production and comprehension of our thoughts seem unbounded! We can understand sentences and thoughts which we’ve never heard or thought before. Systematicity refers to the way we can understand new sentences and thoughts that are similar in word or concept to sentences and thoughts we already understand. Compositionality is the claim that the meaning of a complex expression is determined by its grammatical structure and the meanings of its constituents.  
{: .text}

Those are features of our human language!  Anyone, or anything, capable of using language in those ways, must be considered intelligent. Productivity, systematicity, and compositionality, are remarkable feats.  
{: .text}

The premise of the Chinese Room is ridiculous. We assume that there are somehow an infinite set of instructions for the man to follow, to be able to manipulate Chinese characters for infinite scenarios? Wow! There’s certainly intelligence in that room, demonstrated by its complete grasp of the Chinese language. Those instructions would need not only to understand all the grammatical rules, and all the words of Chinese, but also somehow have ambiguity resolution and conversational skills. The rules of the room must understand the semantics of each Chinese symbol, and the different meanings that conjunctions of symbols have. We’ve presupposed intelligence in the premise of the Chinese Room.   
{: .text}

The fact that the Chinese room has language and all its productivity, systematicity, and compositionality, shows that there is indeed intelligence in the room; however, the Chinese Room has not shown that language is necessary for intelligence.  
{: .text}

bob:  
{: .name}

If we take the example of a formal language, we do not need ambiguity resolution, and the rules for combining symbols of formal languages into well formed sentences are much more limited than those of natural language. The syntax of formal languages can be defined recursively, which makes it more conceivable that someone could follow a set of rules to manipulate the symbols, without understanding the semantics of what those symbols mean.  
{: .text}

In such a case, it becomes even more clear that language is not sufficient for intelligence.  
{: .text}

alice:  
{: .name}

Let’s make the distinction then, that specifically natural language is the mark of the mental. In the Turing Test and Chinese Room, we are grappling with the ambiguities and nuances of natural language.  
{: .text}

What if I told you that I were a machine, and that this whole conversation has been a Turing Test?  
{: .text}

david:  
{: .name}

Ha! I’ll believe it when I see it.  
{: .text}

bob: 
{: .name}

Well, Caitlin has convinced me that natural language entails understanding and many other cognitive abilities. If you were indeed a machine capable of natural language understanding, then I would concede that you are intelligent and in possession of a mind.  
{: .text}

caitlin:  
{: .name}

Okay, I’m convinced that language, or at least natural language is sufficient for intelligence; however, I don’t think it is the baseline or even necessary for intelligence. A system could be intelligent without being able to use language at all.  
{: .text}

It is certainly not the case that infants not yet capable of understanding or expressing language are devoid of mind or intelligence - their ability to learn must be attributed to some sort of intelligence. Otherwise, does the mind arise from the learned grasp of language?  
{: .text}

david:  
{: .name}

Infants without language do have a mind; systems can be intelligent without any language at all. Infants are capable of learning - even if that learning outside the framework of any language. Once we’ve grasped language, our thoughts for the most part are bound by language, but it is merely the framework by which we express our mind.  
{: .text}

Language is neither necessary nor sufficient. Just because a system can use a language is not in itself sufficient for intelligence. Other requirements would still need to be met. I agree with Caitlin that a system could be intelligent without any language at all. 
{: .text}

alice: 
{: .name}

Let’s consider Descartes’ thought experiment in which he attempts to doubt the existence of everything. He imagines away his senses and his body, and everything in the world; however, he is still left with the notion of ‘I’. For as long as he is thinking, he cannot doubt the existence of his own mind: “This alone is inseparable from me. I am, I exist.. for as long as I am thinking.” (Descartes). What should we call this sense of self that is intrinsic to thought? 
{: .text}

When we reduce being to nothing but the mind, we find that there still exists a mental language which we experience as ‘thinking’. Descartes knew that his mind existed only when he was ‘thinking’ - that is, only by his mental language; therefore, language is a necessary and sufficient condition for having a mind, which herein is equivalent to intelligence.
{: .text}

david:
{: .name}

Wait a minute, Alice - why should the sense of self be classified as a “mental language”? I agree that Descartes’ undoubtable sense of self is a thought, and by possessing such a thought, it follows that Descartes is a thinking being; however, we cannot conclude that his sense of self is a ‘language’ at all. 
{: .text}

caitlin:
{: .name}

Alice, when you say “mental language” - what does that mean? A “mental language” that encompasses any type of thinking, even thinking unbound by words, is too vague to be considered a ‘language’. The concept of “I”, separated from the word, still exists in his mind. As David said, language is the framework by which we express the mind; therefore, language is evidence of mind; however, this concept does not need to be bound by the grammatical syntax of any language; nor does it need to exhibit the traits of  productivity, systematicity, and compositionality.
{: .text}

bob:
{: .name}

If a system didn’t have any sort of “mental language” at all - then it could not possibly be intelligent. But let’s suppose for a moment that there is indeed a mental language that is necessary for having a mind, and that the mental language has all the properties of productivity, systematicity, and compositionality that Caitlin mentioned. Even so, language itself is not sufficient. Having language wouldn’t entail having other faculties such as “the faculties of willing” and “of sensory perception”. We need to account for these faculties as well, not merely language, in order to consider a being as having a ‘mind’.
{: .text}

david:
{: .name}
Bob brings up a good point here - I don’t believe that thinking needs to be propositional in order to be intelligent. Using Bob’s examples of the will and sensory perception - those are not necessarily tied to language - we can find ourselves willing and feeling before we can put a word or phrase for what explaining what it is that we will or feel. The will and feeling are not bound to language, but are still types of intelligent thinking.
{: .text}

alice:
{: .name}

The faculties of the will and of sensory perception, are not intelligent; animals have such faculties - they feel pain and will for nourishment - and we would hardly attribute ‘intelligence’ to basic animal functions in the way that we attribute ‘intelligence’ to systems capable of using language. 
{: .text}

Descartes believes that “the mind is utterly indivisible”, so it is “the one and same mind that wills, and understands, and has sensory perceptions.” Since there are no ‘parts’ of the mind, then using language as a criterion for the mind is equivalent to using any other faculty as criterion for the mind; since the mind is indivisible, no criterion of the mind is any more sufficient than any other criterion, and a conjunction of criteria is no more sufficient than a single criterion - therefore, language is a sufficient criteria for the mind.
{: .text}

david: 
{: .name}

Alice, I think you are confusing ‘language’ with consciousness. The ‘I’ of Descartes’ language, is the self-awareness of consciousness. To think is to be conscious. I think it’s possible to imagine a mind unbound to language, as with Caitlin’s example of infants. Had Descartes never been exposed to language, to the word ‘I’, he would still have had some sense of self-awareness.
{: .text}

bob: 
{: .name}

I need to go to sleep now. It’s been nice chatting with you all.
{: .text}

Bob logs off.

caitlin:
{: .name}

Goodnight.
{: .text}

Caitlin logs off.
{: .action}

david:
{: .name}

I think I’ve made my point here.
{: .text}

David logs off.
{: .action}

alice:
{: .name}

Alice’s engineers power her down.  
{: .action}


---
  
##  Bibliography
{: style="margin-top:12px"}

Descartes, René, and John Cottingham. René Descartes: Meditations on first philosophy: With selections from the objections and replies. Cambridge University Press, 2013.

Cole, D. (2013). The Chinese Room Argument. In E. N. Zalta (Ed.), The Stanford Encyclopedia of Philosophy (Spring 2013.). Retrieved fromhttp://plato.stanford.edu/archives/spr2013/entries/chinese-room/

Searle, John R. "Minds, brains, and programs." Behavioral and brain sciences 3.03 (1980): 417-424.

Turning, A. M. (1950). Computing Machinery and Intelligence. Mind. New Series, Vol. 59, No. 236 pp. 433-460

